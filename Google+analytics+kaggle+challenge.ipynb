{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Analytics Kaggle Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import json \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'D:/000_Projects_2018/0002_Development/Kaggle/google_analytics/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_json(series: pd.Series) -> pd.DataFrame():\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        series: Series before json parsing \n",
    "\n",
    "    Returns: DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO: Write TypeException\n",
    "    \n",
    "    if isinstance(series[0], str):\n",
    "        return pd.DataFrame(json.loads(s) for s in series)\n",
    "    return pd.DataFrame(s for s in series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Transform Load: ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_col = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "nest_json_col = ['adwordsClickInfo']\n",
    "\n",
    "df_train = pd.read_csv('{}train.csv'.format(data_path), engine='python')\n",
    "df_train = df_train.join(separate_json(\n",
    "    df_train[col_name]) for col_name in json_col).drop(json_col, axis=1)\n",
    "df_train = df_train.join(separate_json(\n",
    "    df_train[nest_json_col[0]])).drop(nest_json_col, axis=1)\n",
    "\n",
    "df_test = pd.read_csv('{}test.csv'.format(data_path), engine='python')\n",
    "df_test = df_test.join(separate_json(\n",
    "    df_test[col_name]) for col_name in json_col).drop(json_col, axis=1)\n",
    "df_test = df_test.join(separate_json(\n",
    "    df_test[nest_json_col[0]])).drop(nest_json_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 56 columns\n",
      "The test dataset has 54 columns\n",
      "The number of rows in the train dataset:903653\n",
      "The number of rows in the test dataset:804684\n"
     ]
    }
   ],
   "source": [
    "print(\"The train dataset has {} columns\".format(len(df_train.columns)))\n",
    "print(\"The test dataset has {} columns\".format(len(df_test.columns)))\n",
    "print(\"The number of rows in the train dataset:{}\".format(len(df_train)))\n",
    "print(\"The number of rows in the test dataset:{}\".format(len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train_naidu = pd.read_csv('{}extracted_fields_train.csv'.format(data_path), engine='python')\n",
    "#df_test_naidu = pd.read_csv('{}extracted_fields_test.csv'.format(data_path), engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"The train dataset has {} columns\".format(len(df_train_naidu.columns)))\n",
    "#print(\"The test dataset has {} columns\".format(len(df_test_naidu.columns)))\n",
    "#print(\"The number of rows in the train dataset:{}\".format(len(df_train_naidu)))\n",
    "#print(\"The number of rows in the test dataset:{}\".format(len(df_test_naidu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transactionRevenue\n",
      "campaignCode\n"
     ]
    }
   ],
   "source": [
    "for column in list(df_train.columns):\n",
    "    if column not in list(df_test.columns):\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224436dfe5c24435a7eadb399a0b381a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='x', max=55), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f4(x):\n",
    "    print(\"x: column nr.{} in the training set which is {}\".format(x,list(df_train.columns)[x]))\n",
    "    print(df_train[list(df_train.columns)[x]].value_counts(dropna=False))\n",
    "\n",
    "interact(f4, x=widgets.IntSlider(min=0,max=len(df_train.columns)-1,step=1,value=0));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b4359b9d614e32a3ef89b01e8e462a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='x', max=53), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f5(x):\n",
    "    print(\"x: column nr.{} in the test set which is {}\".format(x,list(df_test.columns)[x]))\n",
    "    print(df_test[list(df_test.columns)[x]].value_counts(dropna=False))\n",
    "\n",
    "interact(f5, x=widgets.IntSlider(min=0,max=len(df_test.columns)-1,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714167\n",
      "617242\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train.groupby(['fullVisitorId']).sum()))\n",
    "print(len(df_test.groupby(['fullVisitorId']).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullVisitorId_test = df_test.fullVisitorId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_column_to_detet=['fullVisitorId','socialEngagementType','browserSize','browserVersion','flashVersion',\n",
    "                         'language','mobileDeviceBranding','mobileDeviceInfo','mobileDeviceMarketingName',\n",
    "                         'mobileDeviceModel','mobileInputSelector','operatingSystemVersion','screenColors',\n",
    "                          'screenResolution','cityId','latitude','longitude','networkLocation','visits',\n",
    "                          'campaignCode','criteriaParameters','targetingCriteria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_unnecessary_columns(expected_column_to_detet,df_train,df_test):\n",
    "    for col in expected_column_to_detet:\n",
    "        df_train = df_train.drop([col],axis = 1)\n",
    "    for col in expected_column_to_detet:\n",
    "        try:\n",
    "            df_test = df_test.drop([col],axis = 1)\n",
    "        except:\n",
    "            print('Column {} is not exiting in the test dataset'.format(col))\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column campaignCode is not exiting in the test dataset\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = drop_unnecessary_columns(expected_column_to_detet,df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The clean train dataset has 34 columns\n",
      "The clean test dataset has 33 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"The clean train dataset has {} columns\".format(len(df_train.columns)))\n",
    "print(\"The clean test dataset has {} columns\".format(len(df_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11515\n"
     ]
    }
   ],
   "source": [
    "train_revenue = df_train[~df_train['transactionRevenue'].isnull()].copy()\n",
    "print(len(train_revenue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    Y_train = df_train.transactionRevenue\n",
    "    df_train = df_train.drop(['transactionRevenue'],axis = 1)\n",
    "except:\n",
    "    print('the target already deleted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace the strings with integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_strings_integer(df_train, df_test):\n",
    "    df_total = pd.concat([df_train,df_test],sort=False)\n",
    "    df_total.index=range(len(df_total['date']))\n",
    "    df_train_decoded = df_train\n",
    "    df_test_decoded= df_test\n",
    "    for col_i in df_train.columns[df_train.dtypes == 'object']:\n",
    "            \n",
    "        df_total[col_i] = df_total[col_i].factorize()[0]\n",
    "        df_train_decoded[col_i] = df_total.loc[range(df_train.shape[0]),col_i].values\n",
    "        df_test_decoded[col_i] =  df_total.loc[range(df_train.shape[0],\n",
    "                                                     df_train.shape[0]+df_test.shape[0]),\n",
    "                                               col_i].values\n",
    "    return df_train_decoded, df_test_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = replace_strings_integer(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            892138\n",
      "16990000        256\n",
      "18990000        189\n",
      "33590000        187\n",
      "44790000        170\n",
      "13590000        135\n",
      "55990000        122\n",
      "19990000        116\n",
      "15990000         98\n",
      "15190000         93\n",
      "19190000         92\n",
      "10990000         84\n",
      "59990000         81\n",
      "24990000         77\n",
      "79990000         65\n",
      "27190000         64\n",
      "27180000         62\n",
      "33980000         54\n",
      "39990000         51\n",
      "67180000         46\n",
      "1990000          44\n",
      "28780000         40\n",
      "21990000         40\n",
      "30390000         39\n",
      "35980000         39\n",
      "17590000         38\n",
      "27980000         37\n",
      "12990000         37\n",
      "30380000         37\n",
      "31990000         37\n",
      "              ...  \n",
      "122360000         1\n",
      "512370000         1\n",
      "478480000         1\n",
      "166480000         1\n",
      "110320000         1\n",
      "531620000         1\n",
      "201460000         1\n",
      "770000            1\n",
      "215380000         1\n",
      "82240000          1\n",
      "120890000         1\n",
      "30260000          1\n",
      "11700000          1\n",
      "300850000         1\n",
      "37940000          1\n",
      "166950000         1\n",
      "44660000          1\n",
      "223200000         1\n",
      "136750000         1\n",
      "24860000          1\n",
      "68960000          1\n",
      "78300000          1\n",
      "197270000         1\n",
      "201470000         1\n",
      "68180000          1\n",
      "127530000         1\n",
      "15410000          1\n",
      "8680000           1\n",
      "78710000          1\n",
      "399600000         1\n",
      "Name: transactionRevenue, Length: 5333, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Y_train = Y_train.fillna(0)\n",
    "print(Y_train.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.2104403669765169"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_revenue = Y_train[Y_train.astype('int64')>0].copy()\n",
    "min(train_revenue)\n",
    "np.log1p(min(train_revenue.astype('int64')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "## interactive tool\n",
    "col_train = df_train.columns[df_train.dtypes != 'object']\n",
    "col_test = df_test.columns[df_test.dtypes != 'object']\n",
    "print(len(col_train))\n",
    "print(len(col_test))\n",
    "\n",
    "def f(x,print_feature=False):\n",
    "    \n",
    "    compare_columns(x,df_train,df_test,print_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corr_train = df_train.fillna(0).corr()\n",
    "df_corr_test = df_test.fillna(0).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_columns(col_i,df_train,df_test,print_feature):\n",
    "    \n",
    "    col_train = df_train.columns[df_train.dtypes != 'object']\n",
    "    col_test = df_test.columns[df_test.dtypes != 'object']\n",
    "\n",
    "    print('the column {} in both training and testing sets are: '.format(col_i) + \n",
    "          col_train[col_i] +' , ' + col_test[col_i])\n",
    "    print('the mean value of the column {} in both training and testing sets are: '.format(col_i) + \n",
    "          str(df_train[col_train[col_i]].mean()) +' , ' + str(df_test[col_test[col_i]].mean()))\n",
    "    print('the std value of the column {} in both training and testing sets are: '.format(col_i) + \n",
    "          str(df_train[col_train[col_i]].std()) +' , ' + str(df_test[col_test[col_i]].std()))\n",
    "    print('the max value of the column {} in both training and testing sets are: '.format(col_i) + \n",
    "          str(df_train[col_train[col_i]].max()) +' , ' + str(df_test[col_test[col_i]].max()))\n",
    "    print('the min value of the column {} in both training and testing sets are: '.format(col_i) + \n",
    "          str(df_train[col_train[col_i]].min()) +' , ' + str(df_test[col_test[col_i]].min()))\n",
    "    print('Number of uniqe values of the column {}: '.format(col_i) + \n",
    "          str(len(df_train[col_train[col_i]].value_counts())) + '/' + str(len(df_train[col_train[col_i]])) + ' , ' +\n",
    "          str(len(df_test[col_test[col_i]].value_counts())) + '/' + str(len(df_test[col_test[col_i]])))\n",
    "    print('Number of uniqe values of the column {} in both datasets compared to the uniqe values in train set: '.format(col_i) + \n",
    "          str(len(pd.concat([df_train[col_train[col_i]],df_test[col_test[col_i]]]).value_counts())) + '/' +\n",
    "         str(len(df_train[col_train[col_i]].value_counts())))\n",
    "    \n",
    "    print('The most frequent values of the column {} in both datasets: \\n'.format(col_i) + \n",
    "          str(df_train[col_train[col_i]].value_counts().head()) + ' , \\n' +\n",
    "         str(df_test[col_test[col_i]].value_counts().head()))\n",
    "    print ('correlation between the feature and the target')\n",
    "    print(np.corrcoef([df_train[col_train[col_i]].fillna(0),Y_train.astype('int64')]))\n",
    "    plt.matshow(df_corr_train)\n",
    "    \n",
    "    plt.matshow(df_corr_test)\n",
    "    if print_feature:\n",
    "        \n",
    "        plt.scatter(df_train[col_train[0]],df_train[col_train[col_i]],c=Y_train)\n",
    "    \n",
    "    print(df_corr_train.loc[df_corr_train[col_train[col_i]]>0.85,col_train[col_i]].head())\n",
    "    print(df_corr_test.loc[df_corr_test[col_train[col_i]]>0.85,col_train[col_i]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d593ca52454148927b4e2aca16d8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='x', max=32), Checkbox(value=False, description='print_feature'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(f, x=widgets.IntSlider(min=0,max=32,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insights:\n",
    "hists,pageviews have 15 % correlation with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extra_columns_to_delete = ['visitStartTime']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train, df_test = drop_unnecessary_columns(extra_columns_to_delete,df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"The clean train dataset has {} columns\".format(len(df_train.columns)))\n",
    "#print(\"The clean test dataset has {} columns\".format(len(df_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_b = (Y_train.astype('int64') > 0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    892138\n",
      "1     11515\n",
      "Name: transactionRevenue, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_b.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_state = 0\n",
    "#x_train, x_cv, y_train, y_cv= train_test_split(df_train,Y_train_b,\n",
    "#                       test_size=0.1,stratify=Y_train_b,\n",
    "#                       random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(y_train.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(y_cv.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clf = RandomForestClassifier(n_estimators=200,max_depth=15,random_state=0,n_jobs=-1)\n",
    "#clf.fit(x_train, y_train)\n",
    "#print('train:',clf.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print('cross-validation:',clf.score(x_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply classification on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y_test_b = clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(sum(Y_test_b))\n",
    "#print(len(Y_test_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y_train_n = Y_train[Y_train.astype('int64')>0].astype('int64')\n",
    "#df_train_n = df_train[Y_train.astype('int64')>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(Y_train_n.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def f_1(x):\n",
    "#    print(df_train_n.columns[x])\n",
    "#    print('original')\n",
    "#    print(np.corrcoef([df_train_n[df_train_n.columns[x]],Y_train_n]))\n",
    "#    print('log')\n",
    "#    print(np.corrcoef([df_train_n[df_train_n.columns[x]]**2,np.log(Y_train_n)]))\n",
    "    \n",
    "#interact(f_1, x=widgets.IntSlider(min=0,max=31,step=1,value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#column_to_delete = ['bounces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train_n, _ = drop_unnecessary_columns(column_to_delete,df_train_n,df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normaize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train_n_n=(df_train_n-np.mean(df_train_n))/np.std(df_train_n)\n",
    "#df_test_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#linreg = linear_model.LinearRegression()\n",
    "#linreg.fit(df_train_n_n, Y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(linreg.score(df_train_n_n,Y_train_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(df_train_n_n[df_train_n_n.columns[12]],np.log(Y_train_n),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_features(X, map_degree,maped_fea):\n",
    "    V=np.zeros((len(maped_fea),1))\n",
    "    cor_f=pd.DataFrame(maped_fea)\n",
    "    com_x_f=[]\n",
    "    for i in range(2,map_degree+1):\n",
    "        com_x=list(it.combinations_with_replacement(range(1,10), i))#(range(n_x), i))\n",
    "        for j in range(len(com_x)):\n",
    "            if com_x[j][0]!=com_x[j][1] or com_x[j][0]!=com_x[j][1]:\n",
    "                V[:,0]= X[:,com_x[j][0]]*X[:,com_x[j][1]]\n",
    "                cor_f['V']=V\n",
    "                X=np.append(X.T,np.array(X[:,com_x[j][0]]*X[:,com_x[j][1]]).reshape(1,-1),axis=0).T\n",
    "                com_x_f.append(com_x[j])\n",
    "    return X,com_x_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train_map,com_x_f=map_features(np.array(df_train_n_n),2,Y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#linreg.fit(x_train_map, Y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(linreg.score(x_train_map,Y_train_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train_m, x_cv_m, y_train_m, y_cv_m= train_test_split(x_train_map,Y_train_n,\n",
    "#                       test_size=0.1,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "\n",
    "lgb_params = {\"objective\" : \"regression\", \"metric\" : \"rmse\",\n",
    "              \"num_leaves\" : 200, \"learning_rate\" : 0.01, \n",
    "              \"bagging_fraction\" : 0.75, \"feature_fraction\" : 0.8, \"bagging_frequency\" : 9}\n",
    "    \n",
    "#lgb_train = lgb.Dataset(x_train_m, label=np.log(y_train_m))\n",
    "#lgb_val = lgb.Dataset(x_cv_m, label=np.log(y_cv_m))\n",
    "#model = lgb.train(lgb_params, lgb_train, 700, valid_sets=[lgb_val], early_stopping_rounds=150, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "x_train, x_cv, y_train, y_cv= train_test_split(df_train,Y_train.astype('int64'),\n",
    "                       test_size=0.1,stratify=Y_train_b,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_map,com_x_f=map_features(np.array(x_train),2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_features_test(X, com_x_f):\n",
    "    com_x=com_x_f\n",
    "    for j in range(len(com_x)):\n",
    "        X=np.append(X.T,np.array(X[:,com_x[j][0]]*X[:,com_x[j][1]]).reshape(1,-1),axis=0).T\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_cv_map=map_features_test(np.array(x_cv), com_x_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds.\n",
      "[20]\tvalid_0's rmse: 1.90878\n",
      "[40]\tvalid_0's rmse: 1.83538\n",
      "[60]\tvalid_0's rmse: 1.78174\n",
      "[80]\tvalid_0's rmse: 1.74382\n",
      "[100]\tvalid_0's rmse: 1.71541\n",
      "[120]\tvalid_0's rmse: 1.69518\n",
      "[140]\tvalid_0's rmse: 1.68142\n",
      "[160]\tvalid_0's rmse: 1.6695\n",
      "[180]\tvalid_0's rmse: 1.66065\n",
      "[200]\tvalid_0's rmse: 1.65394\n",
      "[220]\tvalid_0's rmse: 1.64888\n",
      "[240]\tvalid_0's rmse: 1.64557\n",
      "[260]\tvalid_0's rmse: 1.64282\n",
      "[280]\tvalid_0's rmse: 1.64041\n",
      "[300]\tvalid_0's rmse: 1.63838\n",
      "[320]\tvalid_0's rmse: 1.63633\n",
      "[340]\tvalid_0's rmse: 1.63458\n",
      "[360]\tvalid_0's rmse: 1.63338\n",
      "[380]\tvalid_0's rmse: 1.63233\n",
      "[400]\tvalid_0's rmse: 1.63178\n",
      "[420]\tvalid_0's rmse: 1.63117\n",
      "[440]\tvalid_0's rmse: 1.63074\n",
      "[460]\tvalid_0's rmse: 1.63078\n",
      "[480]\tvalid_0's rmse: 1.63063\n",
      "[500]\tvalid_0's rmse: 1.63058\n",
      "[520]\tvalid_0's rmse: 1.63044\n",
      "[540]\tvalid_0's rmse: 1.63031\n",
      "[560]\tvalid_0's rmse: 1.63034\n",
      "[580]\tvalid_0's rmse: 1.63032\n",
      "[600]\tvalid_0's rmse: 1.63046\n",
      "[620]\tvalid_0's rmse: 1.63036\n",
      "[640]\tvalid_0's rmse: 1.6304\n",
      "[660]\tvalid_0's rmse: 1.63072\n",
      "[680]\tvalid_0's rmse: 1.6306\n",
      "[700]\tvalid_0's rmse: 1.63029\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(x_train_map, label=np.log1p(y_train))\n",
    "lgb_val = lgb.Dataset(x_cv_map, label=np.log1p(y_cv))\n",
    "model = lgb.train(lgb_params, lgb_train, 700, valid_sets=[lgb_val], early_stopping_rounds=150, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_map=map_features_test(np.array(df_test), com_x_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804684, 69)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804684, 33)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test_map, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804684\n"
     ]
    }
   ],
   "source": [
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sub = pd.DataFrame(fullVisitorId_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sub = pd.DataFrame(columns=['fullVisitorId','PredictedLogRevenue'])\n",
    "#pred_sub.fullVisitorId = fullVisitorId_test\n",
    "pred_sub['PredictedLogRevenue'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x =pred_sub[pred_sub.PredictedLogRevenue < 5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>PredictedLogRevenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6167871330617112363</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0643697640977915618</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6059383810968229466</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2376720078563423631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2314544520795440038</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fullVisitorId  PredictedLogRevenue\n",
       "0  6167871330617112363                  0.0\n",
       "1  0643697640977915618                  0.0\n",
       "2  6059383810968229466                  0.0\n",
       "3  2376720078563423631                  0.0\n",
       "4  2314544520795440038                  0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sub.loc[x,'PredictedLogRevenue']=0\n",
    "pred_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sub.to_csv(data_path+'predict.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sub_agg = pred_sub.groupby(['fullVisitorId']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sub_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(len(pred_sub_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sub_agg.to_csv('{}initial_submission_5.csv'.format(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
