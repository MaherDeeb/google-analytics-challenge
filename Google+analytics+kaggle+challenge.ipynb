{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Analytics Kaggle Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import json \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "import itertools as it\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "maxInt = sys.maxsize\n",
    "decrement = True\n",
    "\n",
    "while decrement:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    decrement = False\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "        decrement = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'D:/000_Projects_2018/0002_Development/Kaggle/google_analytics/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_json(series: pd.Series) -> pd.DataFrame():\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        series: Series before json parsing \n",
    "\n",
    "    Returns: DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO: Write TypeException\n",
    "    \n",
    "    if isinstance(series[0], str):\n",
    "        return pd.DataFrame(json.loads(s) for s in series)\n",
    "    return pd.DataFrame(s for s in series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Transform Load: ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customDimensions\n",
      "device\n",
      "geoNetwork\n",
      "totals\n",
      "trafficSource\n",
      "trafficSource.adwordsClickInfo\n",
      "customDimensions.0\n",
      "trafficSource.adwordsClickInfo.targetingCriteria\n",
      "customDimensions\n",
      "device\n",
      "geoNetwork\n",
      "totals\n",
      "trafficSource\n",
      "trafficSource.adwordsClickInfo\n",
      "customDimensions.0\n",
      "trafficSource.adwordsClickInfo.targetingCriteria\n"
     ]
    }
   ],
   "source": [
    "#json_col = ['customDimensions','device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "json_col = ['customDimensions','device', 'geoNetwork', 'totals', 'trafficSource',\n",
    "            'trafficSource.adwordsClickInfo','customDimensions.0',\n",
    "           'trafficSource.adwordsClickInfo.targetingCriteria']\n",
    "nest_json_col = ['hits']\n",
    "df_train = pd.read_csv('{}train_v2.csv'.format(data_path) ,nrows=2000,engine='python')\n",
    "df_train = df_train.drop('hits',axis=1)\n",
    "df_train ['customDimensions']= df_train['customDimensions'].map(lambda x: str(x).replace(\"\\'\", \"\\\"\"))\n",
    "for col_name in json_col:\n",
    "    print(col_name)\n",
    "    if col_name == 'customDimensions.0':\n",
    "        df_test[col_name]=df_test[col_name].\\\n",
    "        map(lambda x: {'index':'None'} if x is None else x)\n",
    "\n",
    "    df = separate_json(df_train[col_name])\n",
    "    df.columns = ['{}.{}'.format(col_name,x) for x in list(df.columns)]\n",
    "\n",
    "    df_train = df_train.join(df)\n",
    "    df_train = df_train.drop(col_name,axis=1)\n",
    "#df_train.columns\n",
    "\n",
    "df_test = pd.read_csv('{}test_v2.csv'.format(data_path),nrows=2000,engine='python')\n",
    "df_test ['customDimensions']= df_test['customDimensions'].map(lambda x: str(x).replace(\"\\'\", \"\\\"\"))\n",
    "df_test = df_test.drop('hits',axis=1)\n",
    "\n",
    "for col_name in json_col:\n",
    "    print(col_name)\n",
    "    if col_name == 'customDimensions.0':\n",
    "        df_test[col_name]=df_test[col_name].\\\n",
    "        map(lambda x: {'index':'None'} if x is None else x)\n",
    "\n",
    "    df = separate_json(df_test[col_name])\n",
    "    df.columns = ['{}.{}'.format(col_name,x) for x in list(df.columns)]\n",
    "\n",
    "    df_test = df_test.join(df)\n",
    "    df_test = df_test.drop(col_name,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train ['hits']= df_train['hits'].map(lambda x: str(x).replace('\"', \"'\"))\n",
    "#df_train ['hits']= df_train['hits'].map(lambda x: str(x).replace(\"True\", '\"True\"'))\n",
    "#df_train ['hits']= df_train['hits'].map(lambda x: str(x).replace(\"False\", '\"False\"'))\n",
    "#df_train ['hits']= df_train['hits'].map(lambda x: str(x).replace(\"{'\", '{\"'))\n",
    "#df_train ['hits']= df_train['hits'].map(lambda x: str(x).replace(\"'}\", '\"}'))\n",
    "#df_train ['hits']= df_train['hits'].map(lambda x: str(x).replace(\"':\", '\":'))\n",
    "#df_train ['hits']= df_train['hits'].map(lambda x: str(x).replace(\": '\", ': \"'))\n",
    "#df_train ['hits']= df_train['hits'].map(lambda x: str(x).replace(\", '\", ', \"'))\n",
    "#df_train ['hits']= df_train['hits'].map(lambda x: str(x).replace(\"',\", '\",'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(len(df_train.loc[1,'hits']))\n",
    "#print(df_train.loc[443,'hits'][7450  :7550  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = separate_json(df_train[nest_json_col[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(np.sum(df.isnull(),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x = df[df[0].isnull()==False].index\n",
    "#df_t = df.loc[x,0]\n",
    "#df_t.index = range(len(df_t))\n",
    "#print(x)\n",
    "#df1 = separate_json(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df2 = separate_json(df1['contentGroup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['customDimensions.0']=df_train['customDimensions.0'].map(lambda x: '{\"index\":\"1\"}' if '{' not in str(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337    {}\n",
      "464    {}\n",
      "Name: trafficSource.adwordsClickInfo.targetingCriteria.0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x = df_train[df_train['trafficSource.adwordsClickInfo.targetingCriteria.0'].isnull()==False].index\n",
    "#df_train['trafficSource.adwordsClickInfo.targetingCriteria.0'].astype('object').value_counts()\n",
    "print(df_train.loc[x,'trafficSource.adwordsClickInfo.targetingCriteria.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 39 columns\n",
      "The test dataset has 39 columns\n",
      "The number of rows in the train dataset:2000\n",
      "The number of rows in the test dataset:2000\n"
     ]
    }
   ],
   "source": [
    "print(\"The train dataset has {} columns\".format(len(df_train.columns)))\n",
    "print(\"The test dataset has {} columns\".format(len(df_test.columns)))\n",
    "print(\"The number of rows in the train dataset:{}\".format(len(df_train)))\n",
    "print(\"The number of rows in the test dataset:{}\".format(len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train_naidu = pd.read_csv('{}extracted_fields_train.csv'.format(data_path), engine='python')\n",
    "#df_test_naidu = pd.read_csv('{}extracted_fields_test.csv'.format(data_path), engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"The train dataset has {} columns\".format(len(df_train_naidu.columns)))\n",
    "#print(\"The test dataset has {} columns\".format(len(df_test_naidu.columns)))\n",
    "#print(\"The number of rows in the train dataset:{}\".format(len(df_train_naidu)))\n",
    "#print(\"The number of rows in the test dataset:{}\".format(len(df_test_naidu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in list(df_train.columns):\n",
    "    if column not in list(df_test.columns):\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69230b90ef27487093566bc8cd69b60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='x', max=38), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f4(x):\n",
    "    print(\"x: column nr.{} in the training set which is {}\".format(x,list(df_train.columns)[x]))\n",
    "    print(df_train[list(df_train.columns)[x]].value_counts(dropna=False))\n",
    "\n",
    "interact(f4, x=widgets.IntSlider(min=0,max=len(df_train.columns)-1,step=1,value=0));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x =df_train[df_train['totals.transactionRevenue'].fillna(0).astype('int64') > 0].index\n",
    "#df_train.loc[x,'source'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "X=df_train['source'].map(lambda x: (re.match(r'.*youtube.*', str(x).lower()) is not None)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=X*df_train['transactionRevenue'].fillna(0).astype('int64')\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(Y>0)/sum(df_train['transactionRevenue'].fillna(0).astype('int64')>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(re.match(r'.*go+gle.*', str('+Google6').lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39a1e5496df45559e05bffefc349447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='x', max=38), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f5(x):\n",
    "    print(\"x: column nr.{} in the test set which is {}\".format(x,list(df_test.columns)[x]))\n",
    "    print(df_test[list(df_test.columns)[x]].value_counts(dropna=False))\n",
    "\n",
    "interact(f5, x=widgets.IntSlider(min=0,max=len(df_test.columns)-1,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(df_train.groupby(['fullVisitorId']).sum()))\n",
    "print(len(df_test.groupby(['fullVisitorId']).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullVisitorId_test = df_test.fullVisitorId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try:\n",
    "const_cols_train = [c for c in df_train.columns\n",
    "                  if df_train[c].nunique(dropna=False)==1 ]\n",
    "const_cols_test = [c for c in df_test.columns \n",
    "                 if df_test[c].nunique(dropna=False)==1 ]\n",
    "\n",
    "# Drop the columns with constant values\n",
    "df_train = df_train.drop(const_cols_train,\n",
    "                                     axis=1, inplace=False)\n",
    "df_test = df_test.drop(const_cols_test,\n",
    "                                   axis=1, inplace=False)\n",
    "#except:\n",
    "#print(\"problem with the columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_column_to_detet=['fullVisitorId','socialEngagementType','browserSize','browserVersion','flashVersion',\n",
    "                         'language','mobileDeviceBranding','mobileDeviceInfo','mobileDeviceMarketingName',\n",
    "                         'mobileDeviceModel','mobileInputSelector','operatingSystemVersion','screenColors',\n",
    "                          'screenResolution','cityId','latitude','longitude','networkLocation','visits',\n",
    "                          'campaignCode','criteriaParameters','targetingCriteria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(df,column):\n",
    "    \n",
    "    df_ohc = pd.get_dummies(df[column])\n",
    "    df_ohc.columns = ['_'.join((column, str(x))) for x in range(len(df_ohc.columns))]\n",
    "    df = pd.concat([df,df_ohc],axis = 1)\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channelGrouping\n",
      "46\n",
      "46\n",
      "device.deviceCategory\n",
      "49\n",
      "49\n",
      "geoNetwork.continent\n",
      "55\n",
      "55\n",
      "geoNetwork.subContinent\n",
      "74\n",
      "74\n",
      "trafficSource.medium\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "columns = ['channelGrouping','device.deviceCategory',\n",
    "           'geoNetwork.continent', 'geoNetwork.subContinent','trafficSource.medium']\n",
    "\n",
    "for column in columns:\n",
    "    \n",
    "    df_train = one_hot(df_train,column)\n",
    "    df_test = one_hot(df_test,column)\n",
    "    print(column)\n",
    "    print(len(df_train.columns))\n",
    "    print(len(df_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The clean train dataset has {} columns\".format(len(df_train.columns)))\n",
    "print(\"The clean test dataset has {} columns\".format(len(df_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_revenue = df_train[~df_train['transactionRevenue'].isnull()].copy()\n",
    "print(len(train_revenue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    Y_train = df_train.transactionRevenue\n",
    "    df_train = df_train.drop(['transactionRevenue'],axis = 1)\n",
    "except:\n",
    "    print('the target already deleted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace the strings with integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_strings_integer(df_train, df_test):\n",
    "    df_total = pd.concat([df_train,df_test],sort=False)\n",
    "    df_total.index=range(len(df_total['date']))\n",
    "    df_train_decoded = df_train\n",
    "    df_test_decoded= df_test\n",
    "    for col_i in df_train.columns[df_train.dtypes == 'object']:\n",
    "            \n",
    "        df_total[col_i] = df_total[col_i].factorize()[0]\n",
    "        df_train_decoded[col_i] = df_total.loc[range(df_train.shape[0]),col_i].values\n",
    "        df_test_decoded[col_i] =  df_total.loc[range(df_train.shape[0],\n",
    "                                                     df_train.shape[0]+df_test.shape[0]),\n",
    "                                               col_i].values\n",
    "    return df_train_decoded, df_test_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = replace_strings_integer(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = Y_train.fillna(0)\n",
    "print(Y_train.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_revenue = Y_train[Y_train.astype('int64')>0].copy()\n",
    "min(train_revenue)\n",
    "np.log1p(min(train_revenue.astype('int64')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## interactive tool\n",
    "col_train = df_train.columns[df_train.dtypes != 'object']\n",
    "col_test = df_test.columns[df_test.dtypes != 'object']\n",
    "print(len(col_train))\n",
    "print(len(col_test))\n",
    "\n",
    "def f(x,print_feature=False):\n",
    "    \n",
    "    compare_columns(x,df_train,df_test,print_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_corr_train = df_train.fillna(0).corr()\n",
    "df_corr_test = df_test.fillna(0).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_columns(col_i,df_train,df_test,print_feature):\n",
    "    \n",
    "    col_train = df_train.columns[df_train.dtypes != 'object']\n",
    "    col_test = df_test.columns[df_test.dtypes != 'object']\n",
    "\n",
    "    print('the column {} in both training and testing sets are: '.format(col_i) + \n",
    "          col_train[col_i] +' , ' + col_test[col_i])\n",
    "    print('the mean value of the column {} in both training and testing sets are: '.format(col_i) + \n",
    "          str(df_train[col_train[col_i]].mean()) +' , ' + str(df_test[col_test[col_i]].mean()))\n",
    "    print('the std value of the column {} in both training and testing sets are: '.format(col_i) + \n",
    "          str(df_train[col_train[col_i]].std()) +' , ' + str(df_test[col_test[col_i]].std()))\n",
    "    print('the max value of the column {} in both training and testing sets are: '.format(col_i) + \n",
    "          str(df_train[col_train[col_i]].max()) +' , ' + str(df_test[col_test[col_i]].max()))\n",
    "    print('the min value of the column {} in both training and testing sets are: '.format(col_i) + \n",
    "          str(df_train[col_train[col_i]].min()) +' , ' + str(df_test[col_test[col_i]].min()))\n",
    "    print('Number of uniqe values of the column {}: '.format(col_i) + \n",
    "          str(len(df_train[col_train[col_i]].value_counts())) + '/' + str(len(df_train[col_train[col_i]])) + ' , ' +\n",
    "          str(len(df_test[col_test[col_i]].value_counts())) + '/' + str(len(df_test[col_test[col_i]])))\n",
    "    print('Number of uniqe values of the column {} in both datasets compared to the uniqe values in train set: '.format(col_i) + \n",
    "          str(len(pd.concat([df_train[col_train[col_i]],df_test[col_test[col_i]]]).value_counts())) + '/' +\n",
    "         str(len(df_train[col_train[col_i]].value_counts())))\n",
    "    \n",
    "    print('The most frequent values of the column {} in both datasets: \\n'.format(col_i) + \n",
    "          str(df_train[col_train[col_i]].value_counts().head()) + ' , \\n' +\n",
    "         str(df_test[col_test[col_i]].value_counts().head()))\n",
    "    print ('correlation between the feature and the target')\n",
    "    print(np.corrcoef([df_train[col_train[col_i]].fillna(0),Y_train.astype('int64')]))\n",
    "    plt.matshow(df_corr_train)\n",
    "    \n",
    "    plt.matshow(df_corr_test)\n",
    "    if print_feature:\n",
    "        \n",
    "        plt.scatter(df_train[col_train[0]],df_train[col_train[col_i]],c=Y_train)\n",
    "    \n",
    "    print(df_corr_train.loc[df_corr_train[col_train[col_i]]>0.85,col_train[col_i]].head())\n",
    "    print(df_corr_test.loc[df_corr_test[col_train[col_i]]>0.85,col_train[col_i]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interact(f, x=widgets.IntSlider(min=0,max=32,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insights:\n",
    "hists,pageviews have 15 % correlation with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extra_columns_to_delete = ['visitStartTime']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train, df_test = drop_unnecessary_columns(extra_columns_to_delete,df_train,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"The clean train dataset has {} columns\".format(len(df_train.columns)))\n",
    "#print(\"The clean test dataset has {} columns\".format(len(df_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_b = (Y_train.astype('int64') > 0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Y_train_b.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random_state = 0\n",
    "#x_train, x_cv, y_train, y_cv= train_test_split(df_train,Y_train_b,\n",
    "#                       test_size=0.1,stratify=Y_train_b,\n",
    "#                       random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(y_train.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(y_cv.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clf = RandomForestClassifier(n_estimators=200,max_depth=15,random_state=0,n_jobs=-1)\n",
    "#clf.fit(x_train, y_train)\n",
    "#print('train:',clf.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print('cross-validation:',clf.score(x_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply classification on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y_test_b = clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(sum(Y_test_b))\n",
    "#print(len(Y_test_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y_train_n = Y_train[Y_train.astype('int64')>0].astype('int64')\n",
    "#df_train_n = df_train[Y_train.astype('int64')>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(Y_train_n.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def f_1(x):\n",
    "#    print(df_train_n.columns[x])\n",
    "#    print('original')\n",
    "#    print(np.corrcoef([df_train_n[df_train_n.columns[x]],Y_train_n]))\n",
    "#    print('log')\n",
    "#    print(np.corrcoef([df_train_n[df_train_n.columns[x]]**2,np.log(Y_train_n)]))\n",
    "    \n",
    "#interact(f_1, x=widgets.IntSlider(min=0,max=31,step=1,value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#column_to_delete = ['bounces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train_n, _ = drop_unnecessary_columns(column_to_delete,df_train_n,df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normaize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train_n_n=(df_train_n-np.mean(df_train_n))/np.std(df_train_n)\n",
    "#df_test_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#linreg = linear_model.LinearRegression()\n",
    "#linreg.fit(df_train_n_n, Y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(linreg.score(df_train_n_n,Y_train_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(df_train_n_n[df_train_n_n.columns[12]],np.log(Y_train_n),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_features(X, map_degree,maped_fea):\n",
    "    V=np.zeros((len(maped_fea),1))\n",
    "    cor_f=pd.DataFrame(maped_fea)\n",
    "    com_x_f=[]\n",
    "    for i in range(2,map_degree+1):\n",
    "        com_x=list(it.combinations_with_replacement(range(1,10), i))#(range(n_x), i))\n",
    "        for j in range(len(com_x)):\n",
    "            if com_x[j][0]!=com_x[j][1] or com_x[j][0]!=com_x[j][1]:\n",
    "                V[:,0]= X[:,com_x[j][0]]*X[:,com_x[j][1]]\n",
    "                cor_f['V']=V\n",
    "                X=np.append(X.T,np.array(X[:,com_x[j][0]]*X[:,com_x[j][1]]).reshape(1,-1),axis=0).T\n",
    "                com_x_f.append(com_x[j])\n",
    "    return X,com_x_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train_map,com_x_f=map_features(np.array(df_train_n_n),2,Y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#linreg.fit(x_train_map, Y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(linreg.score(x_train_map,Y_train_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train_m, x_cv_m, y_train_m, y_cv_m= train_test_split(x_train_map,Y_train_n,\n",
    "#                       test_size=0.1,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "\n",
    "lgb_params = {\"objective\" : \"regression\", \"metric\" : \"rmse\",\n",
    "              \"num_leaves\" : 200, \"learning_rate\" : 0.01, \n",
    "              \"bagging_fraction\" : 0.75, \"feature_fraction\" : 0.8, \"bagging_frequency\" : 9}\n",
    "    \n",
    "#lgb_train = lgb.Dataset(x_train_m, label=np.log(y_train_m))\n",
    "#lgb_val = lgb.Dataset(x_cv_m, label=np.log(y_cv_m))\n",
    "#model = lgb.train(lgb_params, lgb_train, 700, valid_sets=[lgb_val], early_stopping_rounds=150, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "x_train, x_cv, y_train, y_cv= train_test_split(df_train,Y_train.astype('int64'),\n",
    "                       test_size=0.1,stratify=Y_train_b,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_map,com_x_f=map_features(np.array(x_train),2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_features_test(X, com_x_f):\n",
    "    com_x=com_x_f\n",
    "    for j in range(len(com_x)):\n",
    "        X=np.append(X.T,np.array(X[:,com_x[j][0]]*X[:,com_x[j][1]]).reshape(1,-1),axis=0).T\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_cv_map=map_features_test(np.array(x_cv), com_x_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(x_train_map, label=np.log1p(y_train))\n",
    "lgb_val = lgb.Dataset(x_cv_map, label=np.log1p(y_cv))\n",
    "model = lgb.train(lgb_params, lgb_train, 700, valid_sets=[lgb_val], early_stopping_rounds=150, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_map=map_features_test(np.array(df_test), com_x_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test_map, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sub = pd.DataFrame(fullVisitorId_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sub = pd.DataFrame(columns=['fullVisitorId','PredictedLogRevenue'])\n",
    "#pred_sub.fullVisitorId = fullVisitorId_test\n",
    "pred_sub['PredictedLogRevenue'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x =pred_sub[pred_sub.PredictedLogRevenue < 5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_sub.loc[x,'PredictedLogRevenue']=0\n",
    "pred_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sub.to_csv(data_path+'predict.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sub_agg = pred_sub.groupby(['fullVisitorId']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sub_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(len(pred_sub_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sub_agg.to_csv('{}initial_submission_5.csv'.format(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_external = pd.read_csv('{}SYB61_T29_Internet Usage.csv'.format(data_path), engine='python')\n",
    "df_external.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f4(x):\n",
    "    print(\"x: column nr.{} in the external set which is {}\".format(x,list(df_external.columns)[x]))\n",
    "    print(df_external[list(df_external.columns)[x]].value_counts(dropna=False))\n",
    "\n",
    "interact(f4, x=widgets.IntSlider(min=0,max=len(df_external.columns)-1,step=1,value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
